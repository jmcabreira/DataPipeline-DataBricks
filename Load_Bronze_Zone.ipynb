{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4720f721-0b11-426c-9027-25d17543ef20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Loading Data To Bronze Layer \n",
    "\n",
    "1. The origin of the table dados_arquivo are files and will be loaded in batch using spark. \n",
    "2. The origin of the table dados_api is the sales API and will be loaded in streamming using AutoLoader.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e63e37f-345e-49c9-9ce7-cf8d3c677517",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* Batch Data : Sales from sales consultant - B2B\n",
    "* Streaming Data : API Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e886810-a08e-43d4-86bb-95e290e8a9ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1.0 Initial Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "057a83a2-36e3-471c-bef6-841781186a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The execution of this command did not finish successfully",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"/Users/cabreirajm@gmail.com/DataPipelineCabreira/Helpers/data_generator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6f1d323-316d-48d4-8ba8-9e48d8549ef0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The Data\n",
    "1. **generate_api_data** - This function generate the Sales API streaming data which is in JSON format and is stored in **Landing Zone** : `dbfs:/FileStore/landing/stream/`\n",
    "\n",
    "\n",
    "* The payload struct has information regarding user registration, the sale itself and the payment method. If an user just visit the website without any other action ( registration and selling), all elements will be set as null. \n",
    "\n",
    "An API file example is presented below : \n",
    "\n",
    "```\n",
    "    {\n",
    "        \"access_date\":\"2024-06-02T19:01:09.000Z\",\n",
    "        \"ip_address\":\"207.198.60.166\",\n",
    "        \"access_point\":\"chrome\",\n",
    "        \"payload\":{\n",
    "            \"info_usuario\":{\n",
    "                \"nome\":\"Usuario c3e5d305e1\",\n",
    "                \"idade\":\"44\",\n",
    "                \"sexo\":\"F\",\n",
    "                \"email\":\"usuario_c3e5d305e1@outlook.com\",\n",
    "                \"profissao\":\"Desenvolvedor de ETL\",\n",
    "                \"estado\":\"TO\"\n",
    "            },\n",
    "            \"info_produto\":{\n",
    "                \"product_uuid\":\"f260cd97c6c9813b01601e834a2added\",\n",
    "                \"valor\":\"R$ 589,90\"\n",
    "            },\n",
    "            \"info_pagamento\":{\n",
    "                \"valor\":\"589.90\",\n",
    "                \"forma_pagamento\":\"credito\",\n",
    "                \"quantidade_parcelas\":\"2\",\n",
    "                \"valor_parcelas\":\"294.95\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "```\n",
    "\n",
    "2. **generate_files_data** - This function generates the batch data in csv format. As mentioned above, these csv data are data from sales consultant that sells the products to business ( B2B ). All the data are stored in **Landing Zone** `dbfs:/FileStore/landing/files/`.\n",
    "\n",
    "A batch file example is presented below:\n",
    "\n",
    "```\n",
    "    data_venda,nome_empresa,sexo,nome_funcionario,email_functionario,profissao,idade,estado,curso,valor,disconto\n",
    "    2025-02-26,Empresa A,M,Funcionario 3a0f99b401,funcionario_3a0f99b401@empresaa.com.br,Cientista de Dados,44,RO,Construindo o seu Primeiro Pipeline de Dados com o Databricks,\"R$ 789,90\",5%\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f2b0562-413d-446d-bf12-167636566a3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_api_data-inicio-2024-11-23 09:35:24.478801\ngenerate_api_data-fim-2024-11-23 09:35:28.542894\n              \ngenerate_files_data-inicio-2024-11-23 09:35:28.543169\nO arquivo .csv com 100000 registros foi gerado no diretorio 'dbfs:/FileStore/landing/files'.\ngenerate_files_data-fim-2024-11-23 09:35:45.524093\n              \n"
     ]
    }
   ],
   "source": [
    "# generate api data\n",
    "query = generate_api_data()\n",
    "\n",
    "# generate file data\n",
    "generate_files_data(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d11dc89f-a478-4abe-bc88-9f88264d999d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.0 Create Bronze Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24808ed4-343d-4ab4-92c4-61e260f4c594",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS bronze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85ec9018-2b98-4b79-8835-4b83d0bc1780",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.0 Streaming Data Ingestion to Bronze Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07b712a4-469f-498e-9393-06075982e04a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.1 Read Stream Data as DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fdf77d1-fc71-446b-ad3d-fe8d52a9d25f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using the method **spark.readStream** and the AutoLoader **.format('cloudFiles')** we will be able to read the API streming data with no need of a pre defined schema.\n",
    "\n",
    "* `option('cloudFiles.format', 'json')` : Allows us to read the json data with no need of defining the schema. It is used to identify the file format the Autoloader will process. \n",
    "* `option('cloudFiles.schemaLocation', schema_location_api))`: The local where the infered schema will be stored and versioned.\n",
    "* `option('cloudFiles.inferColumnTypes', True)`: Allows AutoLoader to infer the schema of all columns.\n",
    "* `load(stream_lading_path)`: Creates the readStream processes pointing to the local where the API is sending the streaming data ( the origin path)\n",
    "\n",
    "The `auto_loader_df` dataframe is created below following all the above requirements. In addition, we create two new columns : \n",
    "1. `source_file_name`: Indicates the identifier of the file that originated the registri. \n",
    "2. `processing_timestamp`: The timestamp when the data is ingested and processed. \n",
    "\n",
    "Note thar these two columns are added in order to help in possible debuggings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7029196e-fefa-46a6-94e8-bbcc56fc9409",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>access_date</th><th>access_point</th><th>ip_address</th><th>payload</th><th>_rescued_data</th><th>source_file_name</th><th>processing_timestamp</th></tr></thead><tbody><tr><td>2024-06-02T04:20:11.000Z</td><td>safari</td><td>69.127.75.83</td><td>List(null, null, List(usuario_022d744bd9@hotmail.com, PI, 20, Usuario 022d744bd9, Arquiteto de Dados, F))</td><td>null</td><td>part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json</td><td>2024-11-23T09:36:08.714Z</td></tr><tr><td>2024-06-02T04:53:07.000Z</td><td>android</td><td>168.18.37.100</td><td>List(null, null, null)</td><td>null</td><td>part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json</td><td>2024-11-23T09:36:08.714Z</td></tr><tr><td>2024-06-02T05:26:03.000Z</td><td>firefox</td><td>113.109.66.208</td><td>List(null, null, null)</td><td>null</td><td>part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json</td><td>2024-11-23T09:36:08.714Z</td></tr><tr><td>2024-06-02T05:58:59.000Z</td><td>chrome</td><td>87.241.252.59</td><td>List(null, null, List(usuario_17e7c1bc35@hotmail.com, AP, 20, Usuario 17e7c1bc35, Analista de Dados, F))</td><td>null</td><td>part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json</td><td>2024-11-23T09:36:08.714Z</td></tr><tr><td>2024-06-02T06:31:55.000Z</td><td>iphone</td><td>188.111.120.11</td><td>List(null, null, null)</td><td>null</td><td>part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json</td><td>2024-11-23T09:36:08.714Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2024-06-02T04:20:11.000Z",
         "safari",
         "69.127.75.83",
         [
          null,
          null,
          [
           "usuario_022d744bd9@hotmail.com",
           "PI",
           "20",
           "Usuario 022d744bd9",
           "Arquiteto de Dados",
           "F"
          ]
         ],
         null,
         "part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json",
         "2024-11-23T09:36:08.714Z"
        ],
        [
         "2024-06-02T04:53:07.000Z",
         "android",
         "168.18.37.100",
         [
          null,
          null,
          null
         ],
         null,
         "part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json",
         "2024-11-23T09:36:08.714Z"
        ],
        [
         "2024-06-02T05:26:03.000Z",
         "firefox",
         "113.109.66.208",
         [
          null,
          null,
          null
         ],
         null,
         "part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json",
         "2024-11-23T09:36:08.714Z"
        ],
        [
         "2024-06-02T05:58:59.000Z",
         "chrome",
         "87.241.252.59",
         [
          null,
          null,
          [
           "usuario_17e7c1bc35@hotmail.com",
           "AP",
           "20",
           "Usuario 17e7c1bc35",
           "Analista de Dados",
           "F"
          ]
         ],
         null,
         "part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json",
         "2024-11-23T09:36:08.714Z"
        ],
        [
         "2024-06-02T06:31:55.000Z",
         "iphone",
         "188.111.120.11",
         [
          null,
          null,
          null
         ],
         null,
         "part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json",
         "2024-11-23T09:36:08.714Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "access_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "access_point",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "payload",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"info_pagamento\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"disconto\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"forma_pagamento\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"quantidade_parcelas\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valor\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valor_parcelas\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"info_produto\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"product_uuid\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valor\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"info_usuario\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"estado\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"idade\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"nome\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"profissao\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"sexo\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source_file_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "processing_timestamp",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Reading the API streaming data\n",
    "schema_location_api = 'dbfs:/user/hive/warehouse/bronze.db/_schemas/load_api_raw_data'\n",
    "stream_lading_path  = \"dbfs:/FileStore/landing/stream/\"\n",
    "auto_loader_df = (\n",
    "  spark.readStream\n",
    "       .format('cloudFiles')\n",
    "       .option('cloudFiles.format','json')\n",
    "       .option('cloudFiles.schemaLocation', schema_location_api)\n",
    "       .option('cloudFiles.inferColumnTypes', True)\n",
    "       .load(stream_lading_path)\n",
    ")\n",
    "\n",
    "auto_loader_df = (\n",
    "  auto_loader_df.withColumn(\"source_file_name\", col(\"_metadata.file_name\"))\n",
    "                .withColumn(\"processing_timestamp\", current_timestamp() )\n",
    ")\n",
    "\n",
    "auto_loader_df.limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd70e4c8-88b5-4cd9-b90d-80c3f47b40cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* The `_rescued_data` column contains data that spark couldnt identify during the process of schema evolution. In other words, the autoLoader stores within this column the registers that it was not able to identify its schema.\n",
    "* Example: Changes in data type might be stored since the autolader may not identify the schema evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff2686eb-0f91-4b8c-8d15-de6622aab97b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2 Loading API Stream Data into Bronze Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac783f69-429a-4d74-8a3a-53e833112632",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We will use the `.writeStream` method to write the auto_loader_df into a **bronze.api_data** table - which will be created on the fly through the method `table()`\n",
    "\n",
    "The method `outputMode('append')` means that the data will be appended in the bronze layer table.\n",
    "\n",
    "The `.option('checkpointLocation',api_data_checkpoint_path)` method used to specify the location of the log that will be used by spark to manage the exactly-once semantics.\n",
    "\n",
    "Note that the process specified bellow is async and will be working as streaming until we stop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6101de5-6d51-49ec-bb90-fc9655c04115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">res0: Boolean = true\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">res0: Boolean = true\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs rm -r dbfs:/user/hive/warehouse/bronze.db/api_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8136e379-01e8-4339-be27-4b23817b8dcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7ff7ece9e6e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_data_checkpoint_path = 'dbfs:/user/hive/warehouse/bronze.db/_checkpoint/api_data'\n",
    "(\n",
    "    auto_loader_df\n",
    "        .writeStream\n",
    "        .format('delta')\n",
    "        .outputMode('append')\n",
    "        .option('checkpointLocation',api_data_checkpoint_path)\n",
    "        .table('bronze.api_data')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a4c73d4-1552-44b0-b74e-180b4ba6f9ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.3 Check the bronze Layer Table \n",
    "\n",
    "* The data is being stored in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a86111d6-bcf4-4b08-870a-ef13154b25be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>access_date</th><th>access_point</th><th>ip_address</th><th>payload</th><th>_rescued_data</th><th>source_file_name</th><th>processing_timestamp</th></tr></thead><tbody><tr><td>2024-06-02T04:20:11.000Z</td><td>safari</td><td>69.127.75.83</td><td>List(null, null, List(usuario_022d744bd9@hotmail.com, PI, 20, Usuario 022d744bd9, Arquiteto de Dados, F))</td><td>null</td><td>part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json</td><td>2024-11-23T09:37:34.673Z</td></tr><tr><td>2024-06-02T04:53:07.000Z</td><td>android</td><td>168.18.37.100</td><td>List(null, null, null)</td><td>null</td><td>part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json</td><td>2024-11-23T09:37:34.673Z</td></tr><tr><td>2024-06-02T05:26:03.000Z</td><td>firefox</td><td>113.109.66.208</td><td>List(null, null, null)</td><td>null</td><td>part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json</td><td>2024-11-23T09:37:34.673Z</td></tr><tr><td>2024-06-02T05:58:59.000Z</td><td>chrome</td><td>87.241.252.59</td><td>List(null, null, List(usuario_17e7c1bc35@hotmail.com, AP, 20, Usuario 17e7c1bc35, Analista de Dados, F))</td><td>null</td><td>part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json</td><td>2024-11-23T09:37:34.673Z</td></tr><tr><td>2024-06-02T06:31:55.000Z</td><td>iphone</td><td>188.111.120.11</td><td>List(null, null, null)</td><td>null</td><td>part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json</td><td>2024-11-23T09:37:34.673Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2024-06-02T04:20:11.000Z",
         "safari",
         "69.127.75.83",
         [
          null,
          null,
          [
           "usuario_022d744bd9@hotmail.com",
           "PI",
           "20",
           "Usuario 022d744bd9",
           "Arquiteto de Dados",
           "F"
          ]
         ],
         null,
         "part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json",
         "2024-11-23T09:37:34.673Z"
        ],
        [
         "2024-06-02T04:53:07.000Z",
         "android",
         "168.18.37.100",
         [
          null,
          null,
          null
         ],
         null,
         "part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json",
         "2024-11-23T09:37:34.673Z"
        ],
        [
         "2024-06-02T05:26:03.000Z",
         "firefox",
         "113.109.66.208",
         [
          null,
          null,
          null
         ],
         null,
         "part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json",
         "2024-11-23T09:37:34.673Z"
        ],
        [
         "2024-06-02T05:58:59.000Z",
         "chrome",
         "87.241.252.59",
         [
          null,
          null,
          [
           "usuario_17e7c1bc35@hotmail.com",
           "AP",
           "20",
           "Usuario 17e7c1bc35",
           "Analista de Dados",
           "F"
          ]
         ],
         null,
         "part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json",
         "2024-11-23T09:37:34.673Z"
        ],
        [
         "2024-06-02T06:31:55.000Z",
         "iphone",
         "188.111.120.11",
         [
          null,
          null,
          null
         ],
         null,
         "part-00004-a3c1111d-bc3c-4dda-9b95-fc4fb36260cd-c000.json",
         "2024-11-23T09:37:34.673Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "access_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "access_point",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ip_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "payload",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"info_pagamento\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"disconto\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"forma_pagamento\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"quantidade_parcelas\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valor\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valor_parcelas\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"info_produto\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"product_uuid\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valor\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"info_usuario\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"email\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"estado\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"idade\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"nome\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"profissao\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"sexo\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source_file_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "processing_timestamp",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM bronze.api_data LIMIT 5\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb1d1dc2-ed2c-4217-b8db-2be3821256cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4.0 Batch Data Ingestion to Bronze Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc993931-8640-407d-885b-8299f4992a50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "We will use the `.read` method to read the batch csv data.\n",
    "\n",
    "* `.option('header',True)`: States that the first row of the csv file is a header\n",
    "* `option('sep',\",\")`: States that the columns are comma separated\n",
    "* `load(batch_landing_path)`: Points to the batch data path \n",
    "\n",
    "In addition, we create two new columns : \n",
    "1. `source_file_name`: Indicates the identifier of the file that originated the registri. \n",
    "2. `processing_timestamp`: The timestamp when the data is ingested and processed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad932c35-c3ef-4f1e-9a0a-7dd962b24966",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.1 Read batch Data as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5e37664-3719-4a06-a6d1-c8f712c04f15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "batch_landing_path = 'dbfs:/FileStore/landing/files'\n",
    "file_data = (\n",
    "    spark.read\n",
    "         .format('csv')\n",
    "         .option('header',True)\n",
    "         .option('sep',\",\")\n",
    "         .load(batch_landing_path)\n",
    "    )\n",
    "\n",
    "file_data = (\n",
    "    file_data.withColumn(\"source_file_name\", col(\"_metadata.file_name\"))\n",
    "             .withColumn(\"processing_timestamp\", current_timestamp())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "325ab468-af1f-4dd8-98bc-1db54a316d9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We will now create two new variables:\n",
    "\n",
    "1. **source_file**: Stores the processed file name\n",
    "2. **qnt_rows_file**: Stores the quantity of rows for each processed file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ca70ed1-c19f-46a0-8e72-35f296e84fe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.2 Loading csv Batch Data into Bronze Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d7321e9-1a26-41ae-adcc-f7e8a322f09a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* `write`: Used to write the csv batch data in the `bronze.file_data` table \n",
    "* `saveAsTable('bronze.file_data')` : Used to save the data in the `bronze.file_data` table \n",
    "* `mode('append')`: States that the data will be appended in the `bronze.file_data` table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "812a99f1-5c71-4ae9-ba8a-19c6f6fb320e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">res1: Boolean = true\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">res1: Boolean = true\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs rm -r dbfs:/user/hive/warehouse/bronze.db/file_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d63729ff-944c-402d-8e61-cbb8b0dea8ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>data_venda</th><th>nome_empresa</th><th>sexo</th><th>nome_funcionario</th><th>email_functionario</th><th>profissao</th><th>idade</th><th>estado</th><th>curso</th><th>valor</th><th>disconto</th><th>source_file_name</th><th>processing_timestamp</th></tr></thead><tbody><tr><td>2025-02-26</td><td>Empresa A</td><td>M</td><td>Funcionario 3284054f49</td><td>funcionario_3284054f49@empresaa.com.br</td><td>Cientista de Dados</td><td>44</td><td>RO</td><td>Construindo o seu Primeiro Pipeline de Dados com o Databricks</td><td>R$ 789,90</td><td>5%</td><td>part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv</td><td>2024-11-23T09:39:35.95Z</td></tr><tr><td>2024-07-01</td><td>Empresa A</td><td>F</td><td>Funcionario 85502baecc</td><td>funcionario_85502baecc@empresaa.com.br</td><td>Desenvolvedor de ETL</td><td>31</td><td>AC</td><td>Do Primeiro Pipeline ao Data Lakehouse com o Databricks</td><td>R$ 689,90</td><td>5%</td><td>part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv</td><td>2024-11-23T09:39:35.95Z</td></tr><tr><td>2025-11-23</td><td>Empresa A</td><td>M</td><td>Funcionario cbdc66550c</td><td>funcionario_cbdc66550c@empresaa.com.br</td><td>Desenvolvedor de ETL</td><td>19</td><td>AM</td><td>Construindo Pipelines de Dados usando o Spark Structured Streaming</td><td>R$ 549,90</td><td>5%</td><td>part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv</td><td>2024-11-23T09:39:35.95Z</td></tr><tr><td>2025-04-07</td><td>Empresa A</td><td>F</td><td>Funcionario 348609e786</td><td>funcionario_348609e786@empresaa.com.br</td><td>Analista de Dados</td><td>21</td><td>RR</td><td>Construindo o seu Primeiro Pipeline de Dados com o Databricks</td><td>R$ 789,90</td><td>5%</td><td>part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv</td><td>2024-11-23T09:39:35.95Z</td></tr><tr><td>2024-08-10</td><td>Empresa A</td><td>M</td><td>Funcionario cfe808cdc0</td><td>funcionario_cfe808cdc0@empresaa.com.br</td><td>Arquiteto de Dados</td><td>44</td><td>PA</td><td>Do Primeiro Pipeline ao Data Lakehouse com o Databricks</td><td>R$ 689,90</td><td>5%</td><td>part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv</td><td>2024-11-23T09:39:35.95Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2025-02-26",
         "Empresa A",
         "M",
         "Funcionario 3284054f49",
         "funcionario_3284054f49@empresaa.com.br",
         "Cientista de Dados",
         "44",
         "RO",
         "Construindo o seu Primeiro Pipeline de Dados com o Databricks",
         "R$ 789,90",
         "5%",
         "part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv",
         "2024-11-23T09:39:35.95Z"
        ],
        [
         "2024-07-01",
         "Empresa A",
         "F",
         "Funcionario 85502baecc",
         "funcionario_85502baecc@empresaa.com.br",
         "Desenvolvedor de ETL",
         "31",
         "AC",
         "Do Primeiro Pipeline ao Data Lakehouse com o Databricks",
         "R$ 689,90",
         "5%",
         "part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv",
         "2024-11-23T09:39:35.95Z"
        ],
        [
         "2025-11-23",
         "Empresa A",
         "M",
         "Funcionario cbdc66550c",
         "funcionario_cbdc66550c@empresaa.com.br",
         "Desenvolvedor de ETL",
         "19",
         "AM",
         "Construindo Pipelines de Dados usando o Spark Structured Streaming",
         "R$ 549,90",
         "5%",
         "part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv",
         "2024-11-23T09:39:35.95Z"
        ],
        [
         "2025-04-07",
         "Empresa A",
         "F",
         "Funcionario 348609e786",
         "funcionario_348609e786@empresaa.com.br",
         "Analista de Dados",
         "21",
         "RR",
         "Construindo o seu Primeiro Pipeline de Dados com o Databricks",
         "R$ 789,90",
         "5%",
         "part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv",
         "2024-11-23T09:39:35.95Z"
        ],
        [
         "2024-08-10",
         "Empresa A",
         "M",
         "Funcionario cfe808cdc0",
         "funcionario_cfe808cdc0@empresaa.com.br",
         "Arquiteto de Dados",
         "44",
         "PA",
         "Do Primeiro Pipeline ao Data Lakehouse com o Databricks",
         "R$ 689,90",
         "5%",
         "part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv",
         "2024-11-23T09:39:35.95Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "data_venda",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "nome_empresa",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sexo",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "nome_funcionario",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email_functionario",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "profissao",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "idade",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "estado",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "curso",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "valor",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "disconto",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source_file_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "processing_timestamp",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "  file_data\n",
    "    .write\n",
    "    .format(\"csv\")\n",
    "    .mode('append')\n",
    "    .saveAsTable('bronze.file_data')\n",
    ")\n",
    "\n",
    "spark.sql('SELECT * FROM bronze.file_data LIMIT 5').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddbb7401-5c9c-4ebd-9a41-64443f2dc496",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Duas variáveis serão utilizadas no processo:\n",
    "1. **source_file** - Armazenará o nome do arquivo a ser processado. \n",
    "2. **qtde_rows_arquivo** - Armazenará a quantidade de registros a serem processados com origem no arquivo.\n",
    "\n",
    "\n",
    "We will use those variables in order do identify the files that have already been stored in the table and do the completeness validation to check wheather or not the data from the origin file are stored in the bronze table.\n",
    "\n",
    "If the data has been stored in bronze table, the data will be deleted from the landing zone in order to avoid duplicated data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "215400a5-d781-426f-a360-e5fbfa9f455d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of rows: 200000\nFile Name: part-00000-tid-4386786483019997920-d94540fd-8cb4-4fe4-ac45-e5e62d250e31-377-1-c000.csv\n"
     ]
    }
   ],
   "source": [
    "source_file = file_data.select(\"source_file_name\").distinct().collect()[0]['source_file_name']\n",
    "qtt_rows_files = file_data.count()\n",
    "\n",
    "print('Total of rows:',qtt_rows_files)\n",
    "print('File Name:',source_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b26e9ef0-3dbb-4ee7-b5ab-532f6b08c6f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* Now we are able to check if the total rows are the same ( file and table data)\n",
    "* Once the batch data ingestion does not have **checkpoint**, we have to delete the file loaded to the bronze.file_data from the landing zone.\n",
    "* In order to do that, we have to make sure that the number of rows in the file and in the bronze.file_data are the same.\n",
    "* If so, we delete the file. Otherwise, we have to check the process. \n",
    "\n",
    "Note: This is done, to avoid duplicated data in the bronze layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffc2e65b-59f0-4559-8af0-d6eb283f1482",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qnt of rows in bromze.file_data table: 100000\n"
     ]
    }
   ],
   "source": [
    "  qnt_rows_table = (\n",
    "  spark.sql(f\"\"\"\n",
    "              SELECT COUNT(*) qtde_rows \n",
    "              FROM bronze.file_data\n",
    "              WHERE source_file_name = '{source_file}'\n",
    "              \"\"\")\n",
    "  ).collect()[0]['qtde_rows']\n",
    "  print('Qnt of rows in bromze.file_data table:',qnt_rows_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fac2ec5-8f43-4d01-86be-51619e6e50f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if qnt_rows_table == qtt_rows_files:\n",
    "  dbutils.fs.rm(f'dbfs:/FileStore/landing/files/{source_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41ef24d3-5604-4910-8786-7c4f8da06dca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The command below stops the straming process and delete the landing zone directory in order to avoid extra cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4f77a1f-b09f-4a17-8c19-a50db7b733e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_all_streams-inicio-2024-11-23 09:40:33.446990\nO stream None fui finalizado com sucesso.\nO stream display_query_2 fui finalizado com sucesso.\nO stream generate_api_stream_data fui finalizado com sucesso.\nstop_all_streams-fim-2024-11-23 09:40:34.699965\n              \nclean_up_landing_dir-inicio-2024-11-23 09:40:34.700087\nTodos os arquivos e diretórios dentro de 'dbfs:/FileStore/landing/' foram excluidos com sucesso.\nclean_up_landing_dir-fim-2024-11-23 09:40:36.235517\n              \n"
     ]
    }
   ],
   "source": [
    "stop_all_streams()\n",
    "clean_up_landing_dir()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 771602024729943,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Load_Bronze_Zone",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
