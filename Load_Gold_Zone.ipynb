{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81574298-f441-4f41-aee8-7275eec42cd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# # Loading Data To Gold Zone \n",
    "\n",
    "**This Notebook:**\n",
    "* Load data to Golg Zone of the Data Lake House\n",
    "* Star Schekma and One Big Table Modeling\n",
    "* Creates **`IDENTITY`** column in Databricks delta table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecd3c5b5-8d45-4392-a9f5-73a260112d4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1.0 Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "97e69ae5-8acb-447a-ac48-de146404d808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting dbldatagen\n  Downloading dbldatagen-0.4.0.post1-py3-none-any.whl (122 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.8/122.8 kB 3.6 MB/s eta 0:00:00\nInstalling collected packages: dbldatagen\nSuccessfully installed dbldatagen-0.4.0.post1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%run \"/Users/cabreirajm@gmail.com/DataPipelineCabreira/Helpers/data_generator\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66d62ab8-f059-4ecd-afa5-bb95afed9b19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.0 Create `Gold Zone` Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dd56966-dd4a-4a81-ac81-18e21a99a82c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a35b5d6-0dfc-46a6-a536-493cd285a6c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.0 `Sales Star Schema` Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e59efc0-3761-4546-9e25-fc1431df0e17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Aiming to optimize queries in large datasets, we can use a dimensional model. \n",
    "We will use Ralph Kimball data warehouse principles and build a Star Schema model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "352565aa-3b9a-435b-8621-413a1c0e091a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### `Dimensional Tables`\n",
    "- **dim_calendar** - Dimension with date information\n",
    "- **dim_cod** - Dimensions with codes  - Low cardinality Dimensions (Junk Dimension): \n",
    "  - **user_origin** - API vs. Files\n",
    "  - **access_from** - mobile vs. computer\n",
    "  - **payment_method** - Pix vs. Boleto vs. Cartão\n",
    "  - **percent_discount** - 5% vs. 10% vs. 15%\n",
    "- **dim_courses** - Dimensão responsável por armazenar as informações de Curso.\n",
    "- **dim_user** - Dimensão responsável por armazenar as informações de Alunos.\n",
    "\n",
    "\n",
    "All tables will have a **Surrogate Key (SK)** column that will be creeated with the **`<col_name> BIGINT GENERATED ALWAYS AS IDENTITY`** command. Spark will populate this column in execution time with an incremental value (incremental(1,1). )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20a9aec8-5dc9-4968-84d6-d3e8e50b8931",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.1 `Sale Dimensions`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5dfd8be-7dcf-4a62-b7a3-3ff46861293f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql( \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS gold.dim_calendar(\n",
    "        sk_tempo BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "        date DATE,\n",
    "        year INT, \n",
    "        month STRING,\n",
    "        month_year INT,\n",
    "        day_week_int INT, \n",
    "        day_week STRING,\n",
    "        fl_day_week BOOLEAN,\n",
    "        day_month INT,\n",
    "        fl_last_month_day INT,\n",
    "        day_year INT,\n",
    "        week_year INT,\n",
    "        bimonthly INT,\n",
    "        quarter INT, \n",
    "        semester INT, \n",
    "        dt_load TIMESTAMP\n",
    "    )  \n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS gold.dim_cod (\n",
    "        sk_cod BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "        user_origin STRING,\n",
    "        access_from STRING,\n",
    "        payment_method STRING,\n",
    "        percent_discount STRING,\n",
    "        dt_load TIMESTAMP\n",
    "    )  \n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS gold.dim_course(\n",
    "    sk_course BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "    course_uuid STRING,\n",
    "    course_name STRING, \n",
    "    course_level STRING,\n",
    "    cource_price DECIMAL(9,2),\n",
    "    dt_carga TIMESTAMP\n",
    "\n",
    "    )          \n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS gold.dim_user(\n",
    "    sk_user BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "    user_uuid STRING,\n",
    "    name_user STRING,\n",
    "    user_email STRING,\n",
    "    user_age INT, \n",
    "    user_gender STRING,\n",
    "    user_state STRING,\n",
    "    user_profession STRING,\n",
    "    company STRING,\n",
    "    dt_load\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a15c2fd-cc5d-4570-ab53-41e552ef64cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2 `Calendar Dimension`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "203a1c20-ea0b-4d19-91aa-02052f620db0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The view **`vw_dim_tempo`**:\n",
    "* Starts date : **01/06/2024** \n",
    "* End date: **31/12/2025**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0de37460-82c3-4ae0-b0b9-4844de4c6619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode,sequence,to_date \n",
    "\n",
    "start_date = \"2024-06-01\"\n",
    "end_date = \"2025-12-31\"\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Load_Gold_Zone",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
